<!--- SPDX-License-Identifier: Apache-2.0 -->

## Operator Schemas
*This file is automatically generated from the
            [def files](/onnx/defs) via [this script](/onnx/defs/gen_doc.py).
            Do not modify directly and instead edit operator definitions.*

* ai.onnx.ml (Transformers)
  * <a href="#ai.onnx.ml.Bucketizer">ai.onnx.ml.Bucketizer</a>
  * <a href="#ai.onnx.ml.ChiSqSelector">ai.onnx.ml.ChiSqSelector</a>
  * <a href="#ai.onnx.ml.DCT">ai.onnx.ml.DCT</a>
  * <a href="#ai.onnx.ml.FeatureHasher">ai.onnx.ml.FeatureHasher</a>
  * <a href="#ai.onnx.ml.NGram">ai.onnx.ml.NGram</a>
  * <a href="#ai.onnx.ml.PCA">ai.onnx.ml.PCA</a>
  * <a href="#ai.onnx.ml.StopWordsRemover">ai.onnx.ml.StopWordsRemover</a>
  * <a href="#ai.onnx.ml.Word2Vec">ai.onnx.ml.Word2Vec</a>
* ai.onnx.ml (Classification)
  * <a href="#ai.onnx.ml.NaiveBayes">ai.onnx.ml.NaiveBayes</a>
* ai.onnx.ml (Clustering)
  * <a href="#ai.onnx.ml.KMeans">ai.onnx.ml.KMeans</a>
  * <a href="#ai.onnx.ml.GaussianMixture">ai.onnx.ml.GaussianMixture</a>
  * <a href="#ai.onnx.ml.LDA">ai.onnx.ml.LDA</a>
* ai.onnx.ml (Regression)
  * <a href="#ai.onnx.ml.IsotonicRegression">ai.onnx.ml.IsotonicRegression</a>
## ai.onnx.ml

### <a name="ai.onnx.ml.Bucketizer"></a><a name="ai.onnx.ml.bucketizer">**ai.onnx.ml.Bucketizer**</a>

  Maps a tensor of continuous features to a tensor of feature buckets

#### Internal Notes
Spark ML:
    pyspark.ml.feature.Bucketizer and pyspark.ml.feature.QuantileDiscretizer
Scikit Learn:
    None (however numpy has digitizer)

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.ChiSqSelector"></a><a name="ai.onnx.ml.chisqselector">**ai.onnx.ml.ChiSqSelector**</a>

Chi-Squared feature selection, which selects categorical features to use for predicting a categorical label. The selector supports different selection methods: numTopFeatures, percentile, fpr, fdr, fwe.

 * numTopFeatures chooses a fixed number of top features according to a chi-squared test.
 * percentile is similar but chooses a fraction of all features instead of a fixed number.
 * fpr chooses all features whose p-values are below a threshold, thus controlling the false positive rate of selection.
 * fdr uses the Benjamini-Hochberg procedure to choose all features whose false discovery rate is below a threshold.
 * fwe chooses all features whose p-values are below a threshold. The threshold is scaled by 1/numFeatures, thus controlling the family-wise error rate of selection.

#### Internal Notes
Spark ML:
 * pyspark.ml.feature.ChiSqSelector

Scikit Learn:
 * sklearn.feature_selection.chi2

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.DCT"></a><a name="ai.onnx.ml.dct">**ai.onnx.ml.DCT**</a>

A feature transformer that takes the 1D discrete cosine transform of a real vector.
o zero padding is performed on the input vector. It returns a real vector of the same length representing the DCT.
The return vector is scaled such that the transform matrix is unitary (aka scaled DCT-II)

#### Internal Notes
Spark ML:
 * pyspark.ml.feature.DCT

Scikit Learn:
 * scipy.fftpack.dct

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.FeatureHasher"></a><a name="ai.onnx.ml.featurehasher">**ai.onnx.ml.FeatureHasher**</a>

Feature hashing projects a set of categorical or numerical features into a feature vector of specified dimension
(typically substantially smaller than that of the original feature space).
This is done using the hashing trick (https://en.wikipedia.org/wiki/Feature_hashing) to map features to indices in the feature vector.

#### Internal Notes
Spark ML:
 * pyspark.ml.feature.FeatureHasher

Scikit Learn:
 * sklearn.feature_extraction.FeatureHasher

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.NGram"></a><a name="ai.onnx.ml.ngram">**ai.onnx.ml.NGram**</a>

converts the input array of strings into an array of n-grams. Null values in the input array are ignored.
It returns an array of n-grams where each n-gram is represented by a space-separated string of words.
When the input is empty, an empty array is returned.
When the input array length is less than n (number of elements per n-gram), no n-grams are returned.

#### Internal Notes
Spark ML:
 * pyspark.ml.feature.NGram
 * pyspark.ml.feature.CountVectorizer

Scikit Learn:
 * sklearn.feature_extraction.text.CountVectorizer

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>


### <a name="ai.onnx.ml.PCA"></a><a name="ai.onnx.ml.pca">**ai.onnx.ml.PCA**</a>

Principal component analysis (PCA)

Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.

#### Internal Notes
Spark ML:
 * pyspark.ml.feature.PCA

Scikit Learn:
 * sklearn.decomposition.PCA

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.StopWordsRemover"></a><a name="ai.onnx.ml.stopwordsremover">**ai.onnx.ml.StopWordsRemover**</a>

filters out stop words from input

#### Internal Notes
Spark ML:
 * pyspark.ml.feature.StopWordsRemover

Scikit Learn:
 * implicit in TfidfVectorizer and CountVectorizer

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.Word2Vec"></a><a name="ai.onnx.ml.word2vec">**ai.onnx.ml.Word2Vec**</a>

Transforms a word into a code for further natural language processing or machine learning process.

#### Internal Notes
Spark ML:
 * pyspark.ml.feature.Word2Vec

Scikit Learn:
 * Non-existant (see gensim.sklearn_api.W2VTransformer)

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.NaiveBayes"></a><a name="ai.onnx.ml.naivebayes">**ai.onnx.ml.NaiveBayes**</a>

Naive Bayes Classifiers. It supports both Multinomial and Bernoulli NB.
Multinomial NB can handle finitely supported discrete data.
For example, by converting documents into TF-IDF vectors, it can be used for document classification.
By making every vector a binary (0/1) data, it can also be used as Bernoulli NB.
The input feature values must be nonnegative

#### Internal Notes
Spark ML:
 * pyspark.ml.classification.NaiveBayes

Scikit Learn:
 * sklearn.naive_bayes.BernoulliNB
 * sklearn.naive_bayes.GaussianNB
 * sklearn.naive_bayes.MultinomialNB
 * sklearn.naive_bayes.ComplementNB

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.KMeans"></a><a name="ai.onnx.ml.gaussianmixture">**ai.onnx.ml.KMeans**</a>

K-means clustering with a k-means++ like initialization mode (the k-means|| algorithm by Bahmani et al).

#### Internal Notes
Spark ML:
 * pyspark.ml.clustering.KMeans
 * pyspark.ml.clustering.BisectingKMeans

Scikit Learn:
 * sklearn.cluster.KMeans

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.NaiveBayes"></a><a name="ai.onnx.ml.gaussianmixture">**ai.onnx.ml.GaussianMixture**</a>

GaussianMixture clustering.
This class performs expectation maximization for multivariate Gaussian Mixture Models (GMMs).
A GMM represents a composite distribution of independent Gaussian distributions
with associated “mixing” weights specifying each’s contribution to the composite.

#### Internal Notes
Spark ML:
 * pyspark.ml.clustering.GaussianMixture

Scikit Learn:
 * sklearn.mixture.GaussianMixture

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.LDA"></a><a name="ai.onnx.ml.lda">**ai.onnx.ml.LDA**</a>

Latent Dirichlet Allocation (LDA), a topic model designed for text documents

#### Internal Notes
Spark ML:
 * pyspark.ml.clustering.LDA

Scikit Learn:
 * None

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>

### <a name="ai.onnx.ml.IsotonicRegression"></a><a name="ai.onnx.ml.isotonicregression">**ai.onnx.ml.IsotonicRegression**</a>

Isotonic regression model.

The isotonic regression optimization problem is defined by:

    min sum w_i (y[i] - y_[i]) ** 2

    subject to y_[i] <= y_[j] whenever X[i] <= X[j]
    and min(y_) = y_min, max(y_) = y_max
where:
* y[i] are inputs (real numbers)
* y_[i] are fitted
* X specifies the order. If X is non-decreasing then y_ is non-decreasing.
* w[i] are optional strictly positive weights (default to 1.0)

#### Internal Notes
Spark ML:
 * pyspark.ml.regression.IsotonicRegression

Scikit Learn:
 * sklearn.isotonic.IsotonicRegression

#### Version

This version of the operator has been available since version 1 of the 'ai.onnx.ml' operator set.

#### Attributes

<dl>
<dt><tt>classes_strings</tt> : list of strings</dt>
<dd>List of class label strings to be encoded as int64s</dd>
<dt><tt>default_int64</tt> : int</dt>
<dd>Default value if not in class list as int64</dd>
<dt><tt>default_string</tt> : string</dt>
<dd>Default value if not in class list as string</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd>Data to be encoded</dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd>Encoded output data</dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
<dt><tt>T2</tt> : tensor(string), tensor(int64)</dt>
<dd> allowed types.</dd>
</dl>
